{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discretization\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will deal with continuous state and action spaces by discretizing them. This will enable you to apply reinforcement learning algorithms that are only designed to work with discrete spaces.\n",
    "\n",
    "### 1. Import the Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set plotting options\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "np.set_printoptions(precision=3, linewidth=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Specify the Environment, and Explore the State and Action Spaces\n",
    "\n",
    "We'll use [OpenAI Gym](https://gym.openai.com/) environments to test and develop our algorithms. These simulate a variety of classic as well as contemporary reinforcement learning tasks.  Let's use an environment that has a continuous state space, but a discrete action space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Create an environment and set random seed\n",
    "env = gym.make('MountainCar-v0')\n",
    "env.seed(505);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next code cell to watch a random agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "GLXInfoException",
     "evalue": "pyglet requires an X server with GLX",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mGLXInfoException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-e91246882073>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Python_stuff/anaconda3/envs/RL/lib/python3.6/site-packages/gym/core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Python_stuff/anaconda3/envs/RL/lib/python3.6/site-packages/gym/envs/classic_control/mountain_car.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassic_control\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mViewer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreen_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen_height\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_position\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_position\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Python_stuff/anaconda3/envs/RL/lib/python3.6/site-packages/gym/envs/classic_control/rendering.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Error occured while running `from pyglet.gl import *`\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HINT: make sure you have OpenGL install. On Ubuntu, you can run 'apt-get install python-opengl'. If you're running on a server, you may need a virtual frame buffer; something like this should work: 'xvfb-run -s \\\"-screen 0 1400x900x24\\\" python <your_script.py>'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Python_stuff/anaconda3/envs/RL/lib/python3.6/site-packages/pyglet/gl/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;31m# trickery is for circular import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0m_pyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Python_stuff/anaconda3/envs/RL/lib/python3.6/site-packages/pyglet/window/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   1894\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_pyglet_docgen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1895\u001b[0m     \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1896\u001b[0;31m     \u001b[0mgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_shadow_window\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Python_stuff/anaconda3/envs/RL/lib/python3.6/site-packages/pyglet/gl/__init__.py\u001b[0m in \u001b[0;36m_create_shadow_window\u001b[0;34m()\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWindow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m     \u001b[0m_shadow_window\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWindow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisible\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m     \u001b[0m_shadow_window\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswitch_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Python_stuff/anaconda3/envs/RL/lib/python3.6/site-packages/pyglet/window/xlib/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_handlers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXlibWindow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mglobal\u001b[0m \u001b[0m_can_detect_autorepeat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Python_stuff/anaconda3/envs/RL/lib/python3.6/site-packages/pyglet/window/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, width, height, caption, resizable, style, fullscreen, visible, vsync, display, screen, config, context, mode)\u001b[0m\n\u001b[1;32m    510\u001b[0m                 None]:\n\u001b[1;32m    511\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m                     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemplate_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mNoSuchConfigException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Python_stuff/anaconda3/envs/RL/lib/python3.6/site-packages/pyglet/canvas/base.py\u001b[0m in \u001b[0;36mget_best_config\u001b[0;34m(self, template)\u001b[0m\n\u001b[1;32m    157\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m             \u001b[0mconfigs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_matching_configs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconfigs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNoSuchConfigException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Python_stuff/anaconda3/envs/RL/lib/python3.6/site-packages/pyglet/canvas/xlib.py\u001b[0m in \u001b[0;36mget_matching_configs\u001b[0;34m(self, template)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_matching_configs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemplate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mcanvas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXlibCanvas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mconfigs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemplate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;31m# XXX deprecate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfigs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Python_stuff/anaconda3/envs/RL/lib/python3.6/site-packages/pyglet/gl/xlib.py\u001b[0m in \u001b[0;36mmatch\u001b[0;34m(self, canvas)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglx_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGLXInfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_display\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mhave_13\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhave_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhave_13\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mconfig_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXlibCanvasConfig13\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Python_stuff/anaconda3/envs/RL/lib/python3.6/site-packages/pyglet/gl/glx_info.py\u001b[0m in \u001b[0;36mhave_version\u001b[0;34m(self, major, minor)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_display\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mglXQueryExtension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mGLXInfoException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pyglet requires an X server with GLX'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mserver_version\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_server_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mGLXInfoException\u001b[0m: pyglet requires an X server with GLX"
     ]
    }
   ],
   "source": [
    "state = env.reset()\n",
    "score = 0\n",
    "for t in range(200):\n",
    "    action = env.action_space.sample()\n",
    "    env.render()\n",
    "    state, reward, done, _ = env.step(action)\n",
    "    score += reward\n",
    "    if done:\n",
    "        break \n",
    "print('Final score:', score)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you will train an agent to perform much better!  For now, we can explore the state and action spaces, as well as sample them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State space: Box(2,)\n",
      "- low: [-1.2  -0.07]\n",
      "- high: [ 0.6   0.07]\n"
     ]
    }
   ],
   "source": [
    "# Explore state (observation) space\n",
    "print(\"State space:\", env.observation_space)\n",
    "print(\"- low:\", env.observation_space.low)\n",
    "print(\"- high:\", env.observation_space.high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State space samples:\n",
      "[[-0.133  0.048]\n",
      " [ 0.344  0.049]\n",
      " [-0.078 -0.016]\n",
      " [-0.664 -0.062]\n",
      " [-0.709 -0.003]\n",
      " [ 0.262 -0.003]\n",
      " [-0.493  0.047]\n",
      " [-0.593  0.021]\n",
      " [-0.537  0.064]\n",
      " [-0.947  0.052]]\n"
     ]
    }
   ],
   "source": [
    "# Generate some samples from the state space \n",
    "print(\"State space samples:\")\n",
    "print(np.array([env.observation_space.sample() for i in range(10)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action space: Discrete(3)\n",
      "Action space samples:\n",
      "[0 1 1 2 0 1 1 1 0 2]\n"
     ]
    }
   ],
   "source": [
    "# Explore the action space\n",
    "print(\"Action space:\", env.action_space)\n",
    "\n",
    "# Generate some samples from the action space\n",
    "print(\"Action space samples:\")\n",
    "print(np.array([env.action_space.sample() for i in range(10)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Discretize the State Space with a Uniform Grid\n",
    "\n",
    "We will discretize the space using a uniformly-spaced grid. Implement the following function to create such a grid, given the lower bounds (`low`), upper bounds (`high`), and number of desired `bins` along each dimension. It should return the split points for each dimension, which will be 1 less than the number of bins.\n",
    "\n",
    "For instance, if `low = [-1.0, -5.0]`, `high = [1.0, 5.0]`, and `bins = (10, 10)`, then your function should return the following list of 2 NumPy arrays:\n",
    "\n",
    "```\n",
    "[array([-0.8, -0.6, -0.4, -0.2,  0.0,  0.2,  0.4,  0.6,  0.8]),\n",
    " array([-4.0, -3.0, -2.0, -1.0,  0.0,  1.0,  2.0,  3.0,  4.0])]\n",
    "```\n",
    "\n",
    "Note that the ends of `low` and `high` are **not** included in these split points. It is assumed that any value below the lowest split point maps to index `0` and any value above the highest split point maps to index `n-1`, where `n` is the number of bins along that dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.8,\n",
       "  -0.6,\n",
       "  -0.3999999999999999,\n",
       "  -0.19999999999999996,\n",
       "  0.0,\n",
       "  0.20000000000000018,\n",
       "  0.40000000000000013,\n",
       "  0.6000000000000001,\n",
       "  0.8],\n",
       " [-4.0, -3.0, -2.0, -1.0, 0.0, 1.0, 2.0, 3.0, 4.0]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_uniform_grid(low, high, bins=(10, 10)):\n",
    "    \"\"\"Define a uniformly-spaced grid that can be used to discretize a space.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    low : array_like\n",
    "        Lower bounds for each dimension of the continuous space.\n",
    "    high : array_like\n",
    "        Upper bounds for each dimension of the continuous space.\n",
    "    bins : tuple\n",
    "        Number of bins along each corresponding dimension.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    grid : list of array_like\n",
    "        A list of arrays containing split points for each dimension.\n",
    "    \"\"\"\n",
    "    # TODO: Implement this\n",
    "    #pass\n",
    "    # AE: going through the dimensions of the bins and creating a new array for each\n",
    "    # AE: dimension so that it is evenly split into the specified chunks (-2 chunks as\n",
    "    # AE: per the rules)\n",
    "    res = []\n",
    "    for dim_ndx, dim_val in enumerate(bins):\n",
    "        step = (high[dim_ndx] - low[dim_ndx]) / dim_val\n",
    "\n",
    "        discr = [low[dim_ndx] + step * (dscr_step + 1) for dscr_step in range(bins[dim_ndx] - 1)]\n",
    "        res.append(discr)\n",
    "\n",
    "    return res\n",
    "\n",
    "low = [-1.0, -5.0]\n",
    "high = [1.0, 5.0]\n",
    "create_uniform_grid(low, high)  # [test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now write a function that can convert samples from a continuous space into its equivalent discretized representation, given a grid like the one you created above. You can use the [`numpy.digitize()`](https://docs.scipy.org/doc/numpy-1.9.3/reference/generated/numpy.digitize.html) function for this purpose.\n",
    "\n",
    "Assume the grid is a list of NumPy arrays containing the following split points:\n",
    "```\n",
    "[array([-0.8, -0.6, -0.4, -0.2,  0.0,  0.2,  0.4,  0.6,  0.8]),\n",
    " array([-4.0, -3.0, -2.0, -1.0,  0.0,  1.0,  2.0,  3.0,  4.0])]\n",
    "```\n",
    "\n",
    "Here are some potential samples and their corresponding discretized representations:\n",
    "```\n",
    "[-1.0 , -5.0] => [0, 0]\n",
    "[-0.81, -4.1] => [0, 0]\n",
    "[-0.8 , -4.0] => [1, 1]\n",
    "[-0.5 ,  0.0] => [2, 5]\n",
    "[ 0.2 , -1.9] => [6, 3]\n",
    "[ 0.8 ,  4.0] => [9, 9]\n",
    "[ 0.81,  4.1] => [9, 9]\n",
    "[ 1.0 ,  5.0] => [9, 9]\n",
    "```\n",
    "\n",
    "**Note**: There may be one-off differences in binning due to floating-point inaccuracies when samples are close to grid boundaries, but that is alright."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples:\n",
      "array([[-1.  , -5.  ],\n",
      "       [-0.81, -4.1 ],\n",
      "       [-0.8 , -4.  ],\n",
      "       [-0.5 ,  0.  ],\n",
      "       [ 0.2 , -1.9 ],\n",
      "       [ 0.8 ,  4.  ],\n",
      "       [ 0.81,  4.1 ],\n",
      "       [ 1.  ,  5.  ]])\n",
      "\n",
      "Discretized samples:\n",
      "array([[0, 0],\n",
      "       [0, 0],\n",
      "       [0, 0],\n",
      "       [2, 4],\n",
      "       [5, 3],\n",
      "       [9, 9],\n",
      "       [9, 9],\n",
      "       [9, 9]])\n"
     ]
    }
   ],
   "source": [
    "def discretize(sample, grid):\n",
    "    \"\"\"Discretize a sample as per given grid.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sample : array_like\n",
    "        A single sample from the (original) continuous space.\n",
    "    grid : list of array_like\n",
    "        A list of arrays containing split points for each dimension.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    discretized_sample : array_like\n",
    "        A sequence of integers with the same number of dimensions as sample.\n",
    "    \"\"\"\n",
    "    # TODO: Implement this\n",
    "    #pass\n",
    "    res = []\n",
    "    for dim_ndx, dim in enumerate(grid):\n",
    "        counter = 0\n",
    "\n",
    "        while sample[dim_ndx] > dim[counter] and counter < len(dim) - 1:\n",
    "            counter += 1\n",
    "\n",
    "        if counter == len(dim) - 1: counter += 1\n",
    "        res.append(counter)\n",
    "\n",
    "    return res\n",
    "\n",
    "# Test with a simple grid and some samples\n",
    "grid = create_uniform_grid([-1.0, -5.0], [1.0, 5.0])\n",
    "samples = np.array(\n",
    "    [[-1.0 , -5.0],\n",
    "     [-0.81, -4.1],\n",
    "     [-0.8 , -4.0],\n",
    "     [-0.5 ,  0.0],\n",
    "     [ 0.2 , -1.9],\n",
    "     [ 0.8 ,  4.0],\n",
    "     [ 0.81,  4.1],\n",
    "     [ 1.0 ,  5.0]])\n",
    "discretized_samples = np.array([discretize(sample, grid) for sample in samples])\n",
    "print(\"\\nSamples:\", repr(samples), sep=\"\\n\")\n",
    "print(\"\\nDiscretized samples:\", repr(discretized_samples), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Visualization\n",
    "\n",
    "It might be helpful to visualize the original and discretized samples to get a sense of how much error you are introducing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe14d5957f0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.collections as mc\n",
    "\n",
    "def visualize_samples(samples, discretized_samples, grid, low=None, high=None):\n",
    "    \"\"\"Visualize original and discretized samples on a given 2-dimensional grid.\"\"\"\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    \n",
    "    # Show grid\n",
    "    ax.xaxis.set_major_locator(plt.FixedLocator(grid[0]))\n",
    "    ax.yaxis.set_major_locator(plt.FixedLocator(grid[1]))\n",
    "    ax.grid(True)\n",
    "    \n",
    "    # If bounds (low, high) are specified, use them to set axis limits\n",
    "    if low is not None and high is not None:\n",
    "        ax.set_xlim(low[0], high[0])\n",
    "        ax.set_ylim(low[1], high[1])\n",
    "    else:\n",
    "        # Otherwise use first, last grid locations as low, high (for further mapping discretized samples)\n",
    "        low = [splits[0] for splits in grid]\n",
    "        high = [splits[-1] for splits in grid]\n",
    "\n",
    "    # Map each discretized sample (which is really an index) to the center of corresponding grid cell\n",
    "    grid_extended = np.hstack((np.array([low]).T, grid, np.array([high]).T))  # add low and high ends\n",
    "    grid_centers = (grid_extended[:, 1:] + grid_extended[:, :-1]) / 2  # compute center of each grid cell\n",
    "    locs = np.stack(grid_centers[i, discretized_samples[:, i]] for i in range(len(grid))).T  # map discretized samples\n",
    "\n",
    "    ax.plot(samples[:, 0], samples[:, 1], 'o')  # plot original samples\n",
    "    ax.plot(locs[:, 0], locs[:, 1], 's')  # plot discretized samples in mapped locations\n",
    "    ax.add_collection(mc.LineCollection(list(zip(samples, locs)), colors='orange'))  # add a line connecting each original-discretized sample\n",
    "    ax.legend(['original', 'discretized'])\n",
    "\n",
    "    \n",
    "visualize_samples(samples, discretized_samples, grid, low, high)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a way to discretize a state space, let's apply it to our reinforcement learning environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-1.0200000405311584,\n",
       "  -0.84000003337860107,\n",
       "  -0.6600000262260437,\n",
       "  -0.48000001907348633,\n",
       "  -0.30000001192092896,\n",
       "  -0.12000000476837158,\n",
       "  0.060000002384185791,\n",
       "  0.24000000953674316,\n",
       "  0.42000001668930054],\n",
       " [-0.056000000238418578,\n",
       "  -0.042000000178813932,\n",
       "  -0.028000000119209292,\n",
       "  -0.014000000059604646,\n",
       "  0.0,\n",
       "  0.014000000059604639,\n",
       "  0.028000000119209292,\n",
       "  0.042000000178813932,\n",
       "  0.056000000238418585]]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a grid to discretize the state space\n",
    "state_grid = create_uniform_grid(env.observation_space.low, env.observation_space.high, bins=(10, 10))\n",
    "state_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe14f9ad908>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Obtain some samples from the space, discretize them, and then visualize them\n",
    "state_samples = np.array([env.observation_space.sample() for i in range(10)])\n",
    "discretized_state_samples = np.array([discretize(sample, state_grid) for sample in state_samples])\n",
    "visualize_samples(state_samples, discretized_state_samples, state_grid,\n",
    "                  env.observation_space.low, env.observation_space.high)\n",
    "plt.xlabel('position'); plt.ylabel('velocity');  # axis labels for MountainCar-v0 state space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might notice that if you have enough bins, the discretization doesn't introduce too much error into your representation.  So we may be able to now apply a reinforcement learning algorithm (like Q-Learning) that operates on discrete spaces.  Give it a shot to see how well it works!\n",
    "\n",
    "### 5. Q-Learning\n",
    "\n",
    "Provided below is a simple Q-Learning agent. Implement the `preprocess_state()` method to convert each continuous state sample to its corresponding discretized representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLearningAgent:\n",
    "    \"\"\"Q-Learning agent that can act on a continuous state space by discretizing it.\"\"\"\n",
    "\n",
    "    def __init__(self, env, state_grid, alpha=0.02, gamma=0.99,\n",
    "                 epsilon=1.0, epsilon_decay_rate=0.9995, min_epsilon=.01, seed=505):\n",
    "        \"\"\"Initialize variables, create grid for discretization.\"\"\"\n",
    "        # Environment info\n",
    "        self.env = env\n",
    "        self.state_grid = state_grid\n",
    "        self.state_size = tuple(len(splits) + 1 for splits in self.state_grid)  # n-dimensional state space\n",
    "        self.action_size = self.env.action_space.n  # 1-dimensional discrete action space\n",
    "        self.seed = np.random.seed(seed)\n",
    "        print(\"Environment:\", self.env)\n",
    "        print(\"State space size:\", self.state_size)\n",
    "        print(\"Action space size:\", self.action_size)\n",
    "        \n",
    "        # Learning parameters\n",
    "        self.alpha = alpha  # learning rate\n",
    "        self.gamma = gamma  # discount factor\n",
    "        self.epsilon = self.initial_epsilon = epsilon  # initial exploration rate\n",
    "        self.epsilon_decay_rate = epsilon_decay_rate # how quickly should we decrease epsilon\n",
    "        self.min_epsilon = min_epsilon\n",
    "        \n",
    "        # Create Q-table\n",
    "        self.q_table = np.zeros(shape=(self.state_size + (self.action_size,)))\n",
    "        print(\"Q table size:\", self.q_table.shape)\n",
    "\n",
    "    def preprocess_state(self, state):\n",
    "        \"\"\"Map a continuous state to its discretized representation.\"\"\"\n",
    "        # TODO: Implement this\n",
    "        pass\n",
    "\n",
    "    def reset_episode(self, state):\n",
    "        \"\"\"Reset variables for a new episode.\"\"\"\n",
    "        # Gradually decrease exploration rate\n",
    "        self.epsilon *= self.epsilon_decay_rate\n",
    "        self.epsilon = max(self.epsilon, self.min_epsilon)\n",
    "\n",
    "        # Decide initial action\n",
    "        self.last_state = self.preprocess_state(state)\n",
    "        self.last_action = np.argmax(self.q_table[self.last_state])\n",
    "        return self.last_action\n",
    "    \n",
    "    def reset_exploration(self, epsilon=None):\n",
    "        \"\"\"Reset exploration rate used when training.\"\"\"\n",
    "        self.epsilon = epsilon if epsilon is not None else self.initial_epsilon\n",
    "\n",
    "    def act(self, state, reward=None, done=None, mode='train'):\n",
    "        \"\"\"Pick next action and update internal Q table (when mode != 'test').\"\"\"\n",
    "        state = self.preprocess_state(state)\n",
    "        if mode == 'test':\n",
    "            # Test mode: Simply produce an action\n",
    "            action = np.argmax(self.q_table[state])\n",
    "        else:\n",
    "            # Train mode (default): Update Q table, pick next action\n",
    "            # Note: We update the Q table entry for the *last* (state, action) pair with current state, reward\n",
    "            self.q_table[self.last_state + (self.last_action,)] += self.alpha * \\\n",
    "                (reward + self.gamma * max(self.q_table[state]) - self.q_table[self.last_state + (self.last_action,)])\n",
    "\n",
    "            # Exploration vs. exploitation\n",
    "            do_exploration = np.random.uniform(0, 1) < self.epsilon\n",
    "            if do_exploration:\n",
    "                # Pick a random action\n",
    "                action = np.random.randint(0, self.action_size)\n",
    "            else:\n",
    "                # Pick the best action from Q table\n",
    "                action = np.argmax(self.q_table[state])\n",
    "\n",
    "        # Roll over current state, action for next step\n",
    "        self.last_state = state\n",
    "        self.last_action = action\n",
    "        return action\n",
    "\n",
    "    \n",
    "q_agent = QLearningAgent(env, state_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also define a convenience function to run an agent on a given environment.  When calling this function, you can pass in `mode='test'` to tell the agent not to learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(agent, env, num_episodes=20000, mode='train'):\n",
    "    \"\"\"Run agent in given reinforcement learning environment and return scores.\"\"\"\n",
    "    scores = []\n",
    "    max_avg_score = -np.inf\n",
    "    for i_episode in range(1, num_episodes+1):\n",
    "        # Initialize episode\n",
    "        state = env.reset()\n",
    "        action = agent.reset_episode(state)\n",
    "        total_reward = 0\n",
    "        done = False\n",
    "\n",
    "        # Roll out steps until done\n",
    "        while not done:\n",
    "            state, reward, done, info = env.step(action)\n",
    "            total_reward += reward\n",
    "            action = agent.act(state, reward, done, mode)\n",
    "\n",
    "        # Save final score\n",
    "        scores.append(total_reward)\n",
    "        \n",
    "        # Print episode stats\n",
    "        if mode == 'train':\n",
    "            if len(scores) > 100:\n",
    "                avg_score = np.mean(scores[-100:])\n",
    "                if avg_score > max_avg_score:\n",
    "                    max_avg_score = avg_score\n",
    "\n",
    "            if i_episode % 100 == 0:\n",
    "                print(\"\\rEpisode {}/{} | Max Average Score: {}\".format(i_episode, num_episodes, max_avg_score), end=\"\")\n",
    "                sys.stdout.flush()\n",
    "\n",
    "    return scores\n",
    "\n",
    "scores = run(q_agent, env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best way to analyze if your agent was learning the task is to plot the scores. It should generally increase as the agent goes through more episodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot scores obtained per episode\n",
    "plt.plot(scores); plt.title(\"Scores\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the scores are noisy, it might be difficult to tell whether your agent is actually learning. To find the underlying trend, you may want to plot a rolling mean of the scores. Let's write a convenience function to plot both raw scores as well as a rolling mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scores(scores, rolling_window=100):\n",
    "    \"\"\"Plot scores and optional rolling mean using specified window.\"\"\"\n",
    "    plt.plot(scores); plt.title(\"Scores\");\n",
    "    rolling_mean = pd.Series(scores).rolling(rolling_window).mean()\n",
    "    plt.plot(rolling_mean);\n",
    "    return rolling_mean\n",
    "\n",
    "rolling_mean = plot_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should observe the mean episode scores go up over time. Next, you can freeze learning and run the agent in test mode to see how well it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run in test mode and analyze scores obtained\n",
    "test_scores = run(q_agent, env, num_episodes=100, mode='test')\n",
    "print(\"[TEST] Completed {} episodes with avg. score = {}\".format(len(test_scores), np.mean(test_scores)))\n",
    "_ = plot_scores(test_scores, rolling_window=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also interesting to look at the final Q-table that is learned by the agent. Note that the Q-table is of size MxNxA, where (M, N) is the size of the state space, and A is the size of the action space. We are interested in the maximum Q-value for each state, and the corresponding (best) action associated with that value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_q_table(q_table):\n",
    "    \"\"\"Visualize max Q-value for each state and corresponding action.\"\"\"\n",
    "    q_image = np.max(q_table, axis=2)       # max Q-value for each state\n",
    "    q_actions = np.argmax(q_table, axis=2)  # best action for each state\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    cax = ax.imshow(q_image, cmap='jet');\n",
    "    cbar = fig.colorbar(cax)\n",
    "    for x in range(q_image.shape[0]):\n",
    "        for y in range(q_image.shape[1]):\n",
    "            ax.text(x, y, q_actions[x, y], color='white',\n",
    "                    horizontalalignment='center', verticalalignment='center')\n",
    "    ax.grid(False)\n",
    "    ax.set_title(\"Q-table, size: {}\".format(q_table.shape))\n",
    "    ax.set_xlabel('position')\n",
    "    ax.set_ylabel('velocity')\n",
    "\n",
    "\n",
    "plot_q_table(q_agent.q_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 6. Modify the Grid\n",
    "\n",
    "Now it's your turn to play with the grid definition and see what gives you optimal results. Your agent's final performance is likely to get better if you use a finer grid, with more bins per dimension, at the cost of higher model complexity (more parameters to learn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a new agent with a different state space grid\n",
    "state_grid_new = create_uniform_grid(?, ?, bins=(?, ?))\n",
    "q_agent_new = QLearningAgent(env, state_grid_new)\n",
    "q_agent_new.scores = []  # initialize a list to store scores for this agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train it over a desired number of episodes and analyze scores\n",
    "# Note: This cell can be run multiple times, and scores will get accumulated\n",
    "q_agent_new.scores += run(q_agent_new, env, num_episodes=50000)  # accumulate scores\n",
    "rolling_mean_new = plot_scores(q_agent_new.scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run in test mode and analyze scores obtained\n",
    "test_scores = run(q_agent_new, env, num_episodes=100, mode='test')\n",
    "print(\"[TEST] Completed {} episodes with avg. score = {}\".format(len(test_scores), np.mean(test_scores)))\n",
    "_ = plot_scores(test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the learned Q-table\n",
    "plot_q_table(q_agent_new.q_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Watch a Smart Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()\n",
    "score = 0\n",
    "for t in range(200):\n",
    "    action = q_agent_new.act(state, mode='test')\n",
    "    env.render()\n",
    "    state, reward, done, _ = env.step(action)\n",
    "    score += reward\n",
    "    if done:\n",
    "        break \n",
    "print('Final score:', score)\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
